{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPgrTss+FYOd6XgJPi/3Qvt"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNLE Time Series"
   ],
   "metadata": {
    "id": "Uq1xarZMjyFt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps  # Use colormaps from Matplotlib\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import plotly.express as px\n",
    "from IPython.display import clear_output\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ],
   "metadata": {
    "id": "InNF2BW8YQA2",
    "ExecuteTime": {
     "end_time": "2025-11-25T10:04:10.714650Z",
     "start_time": "2025-11-25T10:04:10.211779Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYfQ-fAojwXI"
   },
   "outputs": [],
   "source": [
    "# In order to access data on Google Drive, you need to mount the drive to access it's content\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load some time series data and do some plotting"
   ],
   "metadata": {
    "id": "BEiWKMoKSlsY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Pandas is used to read a csv file and store data in a DataFrame\n",
    "# Make sure all file are in My Drive, subdirectory Datasets\n",
    "\n",
    "# Read Time Series files:\n",
    "\n",
    "# Airline passengers\n",
    "airline_df = pd.read_csv('airline-passengers.csv')\n",
    "\n",
    "# Daily minimum temperatures Melbourne Australia 1981-1990\n",
    "mintemp_df = pd.read_csv('daily-minimum-temperatures.csv')\n",
    "\n",
    "# Stock prices\n",
    "stock_price_df = pd.read_csv('stocks.csv')\n",
    "# Read the stocks volume data\n",
    "stock_vol_df = pd.read_csv(\"stock_volume.csv\")\n",
    "\n",
    "# Daily total female births\n",
    "# Shampoo sales\n",
    "# Sunspots"
   ],
   "metadata": {
    "id": "U_IJYu-gXsm7",
    "ExecuteTime": {
     "end_time": "2025-11-25T10:04:12.431778Z",
     "start_time": "2025-11-25T10:04:12.396714Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Print Daily minimum temperatures Melbourne Australia 1981-1990\n",
    "print(mintemp_df)"
   ],
   "metadata": {
    "id": "cUu6XmBoPgAJ",
    "ExecuteTime": {
     "end_time": "2025-11-25T10:05:56.952270Z",
     "start_time": "2025-11-25T10:05:56.942449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Temp\n",
      "0     1981-01-01  20.7\n",
      "1     1981-01-02  17.9\n",
      "2     1981-01-03  18.8\n",
      "3     1981-01-04  14.6\n",
      "4     1981-01-05  15.8\n",
      "...          ...   ...\n",
      "3645  1990-12-27  14.0\n",
      "3646  1990-12-28  13.6\n",
      "3647  1990-12-29  13.5\n",
      "3648  1990-12-30  15.7\n",
      "3649  1990-12-31  13.0\n",
      "\n",
      "[3650 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Ensure Date is in datetime format\n",
    "mintemp_df['Date'] = pd.to_datetime(mintemp_df['Date'])"
   ],
   "metadata": {
    "id": "UtHLXbUbWIef"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Daily minimum temperatures Melbourne Australia 1981-1990 with a lin eplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(mintemp_df['Date'], mintemp_df['Temp'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temp')\n",
    "plt.title('Daily minimal temperature - Melbourne Australia')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better visibility\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "YuigAaPDPBGU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Daily minimum temperatures Melbourne Australia 1981-1990 with a dot plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(mintemp_df['Date'], mintemp_df['Temp'], color='black', s=15, alpha=0.20)  # Use black dots\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temp')\n",
    "plt.title('Daily minimal temperature - Melbourne Australia')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better visibility\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "SYy0JDjKomEa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Daily minimum temperatures Melbourne Australia 1981-1990 with a stacked line plot\n",
    "# Ensure the 'Date' column is in datetime format and add day of the year and year columns\n",
    "#mintemp_df['Date'] = pd.to_datetime(mintemp_df['Date'])\n",
    "mintemp_df['DayOfYear'] = mintemp_df['Date'].dt.dayofyear\n",
    "mintemp_df['Year'] = mintemp_df['Date'].dt.year\n",
    "\n",
    "# Group the data by year\n",
    "grouped = mintemp_df.groupby('Year')\n",
    "\n",
    "# Create subplots, one for each year, with reduced height for each plot\n",
    "num_years = grouped.ngroups\n",
    "fig, axes = plt.subplots(num_years, 1, figsize=(12, num_years * 1), sharex=True, sharey=True)\n",
    "\n",
    "# Access the 'tab10' colormap and create evenly spaced colors\n",
    "colors = colormaps['tab10']  # Access colormap directly\n",
    "\n",
    "# Loop through each group and create a line plot\n",
    "for i, ((year, group), ax) in enumerate(zip(grouped, axes)):\n",
    "    ax.plot(group['DayOfYear'], group['Temp'], label=str(year), color=colors(i / (num_years - 1)))  # Normalize color\n",
    "    ax.set_title(f\"Year: {year}\", fontsize=10)\n",
    "    ax.set_ylabel(\"Temp (Â°C)\", fontsize=8)\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "    #ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# Add a shared x-axis label\n",
    "plt.xlabel(\"Day of the Year\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "TxkTzmHUrQ1i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot a heatmap showing seasonality (each year) of daily minimum temperatures Melbourne Australia 1981-1990\n",
    "# Extract year and day of year from the 'Date' column\n",
    "mintemp_df['Year'] = mintemp_df['Date'].dt.year\n",
    "mintemp_df['Day_of_Year'] = mintemp_df['Date'].dt.dayofyear\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "heatmap_data = mintemp_df.pivot_table(index='Year', columns='Day_of_Year', values='Temp', aggfunc='mean')\n",
    "\n",
    "# Create the heatmap using Seaborn\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', cbar_kws={'label': 'Temp'})\n",
    "plt.title('Temperature Heatmap - Melbourne Australia')\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Year')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "1QgCRHIIUfZ6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show a lag plot to show relation between values at timestamp t and values at the next timestamp t+1\n",
    "\n",
    "lagvalue = 1\n",
    "lag_plot(mintemp_df['Temp'], lag=lagvalue)\n",
    "# Customize plot labels and title\n",
    "plt.title('Lag Plot (lag=' + str(lagvalue) + ') daily minimal temperature - Melbourne Australia 1981-1990')\n",
    "plt.xlabel('Value(t)')\n",
    "plt.ylabel('Value(t + ' + str(lagvalue) + ')')\n",
    "\n",
    "# Clear the output in Google Colab\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Qcvre0fjZIj8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the correlation value temperatures\n",
    "# So we calculate the correlation between all daily temperatures at timestamp t\n",
    "# compared with all daily temperatures at timestamp t + lag\n",
    "\n",
    "def calc_corr(lagvalue):\n",
    "  # Create a lagged version of the 'Temperature' column (shifted by one day)\n",
    "  lag_value = lagvalue\n",
    "  mintemp_lagged_df = mintemp_df\n",
    "  mintemp_lagged_df['Temp_lagged'] = mintemp_df['Temp'].shift(lag_value)\n",
    "\n",
    "  # Drop the NaN row resulting from the shift operation\n",
    "  mintemp_lagged_df = mintemp_lagged_df.dropna()\n",
    "\n",
    "  # Calculate the correlation between 'Temp' and 'Temp_lagged'\n",
    "  correlation = mintemp_lagged_df['Temp'].corr(mintemp_lagged_df['Temp_lagged'])\n",
    "\n",
    "  return correlation\n",
    "\n",
    "# Print the correlation value\n",
    "# print(f\"Correlation between daily temperature and lagged temperature (lag = {lag_value}): {correlation}\")"
   ],
   "metadata": {
    "id": "KrQ26t3Hd3s1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show a lag plot to show relation between values at timestamp t and values at the next timestamp t+1\n",
    "\n",
    "max_lags = 365 # set the maximum lag value to plot, 365 would be a whole year\n",
    "step_lags = 7 # set the step size for the lag values, 7 would be a week\n",
    "\n",
    "for lagvalue in range(1, max_lags, step_lags):\n",
    "    lag_plot(mintemp_df['Temp'], lag=lagvalue)\n",
    "    # Customize plot labels and title\n",
    "    plt.title('Lag Plot\\nlag=' + str(lagvalue) + '\\nr=' + str(round(calc_corr(lagvalue),2)) + '\\ndaily minimal temperature - Melbourne Australia 1981-1990')\n",
    "    plt.xlabel('Value(t)')\n",
    "    plt.ylabel('Value(t + ' + str(lagvalue) + ')')\n",
    "\n",
    "    # Clear the output in Google Colab\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "Wap-TAC6Zo3G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# We can quantify the strength and type of relationships between observations and their lags\n",
    "# This is called correlation\n",
    "# When calculated against lag values in time series, this is called autocorrelation\n",
    "# The autocorrelation plot will show the lag value on the x-axis and the correlation coefficient value on the y-axis\n",
    "\n",
    "autocorrelation_plot(mintemp_df['Temp'])\n",
    "# Customize plot labels and title\n",
    "plt.title('Autocorrelation Plot daily minimal temperature - Melbourne Australia 1981-1990')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Correlation coefficient')\n",
    "\n",
    "# Customize the x-axis to show multiples of 365\n",
    "max_lag = len(mintemp_df['Temp'])  # Maximum lag value\n",
    "step = 365  # Step size for labels\n",
    "ticks = range(0, max_lag, step)  # Generate ticks at multiples of 365\n",
    "plt.xticks(ticks, labels=[str(t) for t in ticks])  # Set ticks and labels\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "u_QbhM8EccZx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "fcXXZD2PYew2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(airline_df)"
   ],
   "metadata": {
    "id": "7E0dFxu7q-rc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot Airline Passengers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(airline_df['Month'], airline_df['Passengers'])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Passengers')\n",
    "plt.title('Monthly airline passengers')\n",
    "ticks = airline_df['Month'][::6]\n",
    "plt.xticks(ticks=ticks, labels=ticks, rotation=45, ha='right')  # Set custom ticks and rotate\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "focotFHKr0Dp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Ensure Date is in datetime format\n",
    "airline_df['Month'] = pd.to_datetime(airline_df['Month'])\n",
    "# Set 'Month' as the index\n",
    "airline_df = airline_df.set_index('Month')"
   ],
   "metadata": {
    "id": "5-lJKmgvtKWD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# decompose airline passengers dataset\n",
    "result = seasonal_decompose(airline_df['Passengers'], model='multiplicative')\n",
    "\n",
    "# Plot the original time series, trend, seasonal, and residual components\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(airline_df['Passengers'], label='Original')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Monthly airline passengers')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(result.trend, label='Trend')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Component')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(result.seasonal, label='Seasonal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(result.resid, label='Residual')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "jVXxfgkhvxmu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict with stock data"
   ],
   "metadata": {
    "id": "vac6VndwJqCH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# print daily stock prices and stock volume of 9 stocks\n",
    "print('Stock price data\\n')\n",
    "print(stock_price_df)\n",
    "print('Stock volume data\\n')\n",
    "print(stock_vol_df)"
   ],
   "metadata": {
    "id": "fufWjojDJ5IT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to plot interactive plots using Plotly Express\n",
    "def interactive_plot(df, title):\n",
    "  fig = px.line(title = title)\n",
    "  for i in df.columns[1:]:\n",
    "    fig.add_scatter(x = df['Date'], y = df[i], name = i)\n",
    "  fig.show()"
   ],
   "metadata": {
    "id": "SyCkunFXKS8-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot interactive chart for stock price data\n",
    "interactive_plot(stock_price_df, 'Stock Prices')"
   ],
   "metadata": {
    "id": "o39wZ0WOKk18"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot interactive chart for stock volume data\n",
    "interactive_plot(stock_vol_df, 'Stock Volumes')"
   ],
   "metadata": {
    "id": "gn-aUWT5M-uM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot interactive chart for stock volume data without S&P 500\n",
    "interactive_plot(stock_vol_df.drop('sp500', axis='columns'), 'Stock Volumes without S&P 500')"
   ],
   "metadata": {
    "id": "eboNJOz3NFGy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict Tesla stock prices"
   ],
   "metadata": {
    "id": "N4LppkSob5yt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "stock_to_predict = 'TSLA'"
   ],
   "metadata": {
    "id": "BwtajbyCcLtf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to concatenate the date, stock price, and volume in one dataframe\n",
    "def individual_stock(price_df, vol_df, name):\n",
    "    return pd.DataFrame({'Date': price_df['Date'], 'Close': price_df[name], 'Volume': vol_df[name]})"
   ],
   "metadata": {
    "id": "vQ7cN7VYNadv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to return the input/output (target) data for AI/ML Model\n",
    "# Note that our goal is to predict the future stock price\n",
    "# Target stock price today will be the stock price 1 working day in the future\n",
    "def trading_window(data):\n",
    "\n",
    "  # 1 day window\n",
    "  n = 1\n",
    "\n",
    "  # Create a column containing the prices for the next 1 days\n",
    "  data['Target'] = data[['Close']].shift(-n)\n",
    "\n",
    "  # return the new dataset\n",
    "  return data"
   ],
   "metadata": {
    "id": "fHTBnfeDNbRn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's test the functions and get individual stock prices and volumes\n",
    "price_volume_df = individual_stock(stock_price_df, stock_vol_df, stock_to_predict)\n",
    "price_volume_df"
   ],
   "metadata": {
    "id": "SaY4KjhTNgLJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Add the target data to the dataframe\n",
    "price_volume_target_df = trading_window(price_volume_df)\n",
    "price_volume_target_df"
   ],
   "metadata": {
    "id": "o3jj0Yb2OoIs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove the last rows as it will be a null value\n",
    "price_volume_target_df = price_volume_target_df.dropna()\n",
    "price_volume_target_df"
   ],
   "metadata": {
    "id": "nEZVDT2LO15N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove Date column\n",
    "full_df = price_volume_target_df.drop(columns = ['Date'])\n",
    "X = full_df.drop(columns = ['Target'])\n",
    "y = full_df['Target']\n",
    "full_df"
   ],
   "metadata": {
    "id": "7ow1SYVroema"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# The autocorrelation plot will show the lag value on the x-axis and the correlation coefficient value on the y-axis\n",
    "\n",
    "autocorrelation_plot(full_df['Target'])\n",
    "# Customize plot labels and title\n",
    "plt.title(f'Autocorrelation Plot {stock_to_predict} stock')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Correlation coefficient')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "NdoHyeWNc78C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split into train and test set\n",
    "split1 = int(0.7 * len(full_df)) # train first 70% prices, test last 30% prices\n",
    "full_df_train = full_df.iloc[:split1]\n",
    "full_df_test = full_df.iloc[split1:]"
   ],
   "metadata": {
    "id": "CoFM1aWwslWF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_train"
   ],
   "metadata": {
    "id": "fWLqOSi5io5v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Scale the data\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "full_df_train_scaled = pd.DataFrame(scaler.fit_transform(full_df_train), columns=full_df_train.columns)\n",
    "\n",
    "# Transform the validation and test sets using the fitted scaler\n",
    "full_df_test_scaled = pd.DataFrame(scaler.transform(full_df_test), columns=full_df_test.columns)"
   ],
   "metadata": {
    "id": "T7L3Np1qto74"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_train_scaled"
   ],
   "metadata": {
    "id": "VXi4agqciH0C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Separate scaled input and output(label)\n",
    "X_train = full_df_train_scaled[['Close', 'Volume']]\n",
    "y_train = full_df_train_scaled['Target']\n",
    "X_test = full_df_test_scaled[['Close', 'Volume']]\n",
    "y_test = full_df_test_scaled['Target']"
   ],
   "metadata": {
    "id": "cWZ8S1FDQMq7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"X : \", X.shape)\n",
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"X_test : \", X_test.shape)"
   ],
   "metadata": {
    "id": "27VwCnD-TKn1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train"
   ],
   "metadata": {
    "id": "4dapyhsflFoV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a data plotting function\n",
    "\n",
    "def show_plot(data, title):\n",
    "  plt.figure(figsize = (13, 5))\n",
    "  plt.plot(data, linewidth = 1)\n",
    "  plt.title(title)\n",
    "  plt.grid()\n",
    "\n",
    "show_plot(X_train, 'Scaled training data')\n",
    "show_plot(X_test, 'Scaled test data')"
   ],
   "metadata": {
    "id": "CKXWlOhvMuTM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform a linear regression\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "\n",
    "# Perform Ridge regression\n",
    "#regression_model = Ridge()\n",
    "\n",
    "# Perform fit\n",
    "regression_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "id": "TUHLZ7aKOUcj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# r2 score\n",
    "train_preds = regression_model.predict(X_train)\n",
    "test_preds = regression_model.predict(X_test)\n",
    "\n",
    "train_accuracy = r2_score(y_train, train_preds)\n",
    "test_accuracy = r2_score(y_test, test_preds)\n",
    "\n",
    "print(\"Train R^2 Accuracy:\", train_accuracy)\n",
    "print(\"Test R^2 Accuracy:\", test_accuracy)"
   ],
   "metadata": {
    "id": "RzbokTML9RXG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_preds"
   ],
   "metadata": {
    "id": "Iv_muPmMGgim"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Put actual training labels and predicted labels in a dataframe\n",
    "# First add the actual value and then delete close and volume columns\n",
    "\n",
    "pred_train_df = pd.DataFrame({'Actual': y_train, 'Predicted': train_preds})\n",
    "pred_test_df = pd.DataFrame({'Actual': y_test, 'Predicted': test_preds})"
   ],
   "metadata": {
    "id": "Hio_Gcli-oB3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show plots\n",
    "\n",
    "show_plot(pred_train_df, 'Scaled prediction training data')\n",
    "show_plot(pred_test_df, 'Scaled prediction test data')"
   ],
   "metadata": {
    "id": "54JLggV595a5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# scale the actual values and predictions back with the fitted scaler\n",
    "# the scaling was done using a 3 columns input, so the inverse scaling needs a 3 columns input too\n",
    "\n",
    "# Take X_train and X_test dataframes and append it with train_preds and test_preds\n",
    "X_train_preds = X_train.copy()\n",
    "X_test_preds = X_test.copy()\n",
    "X_train_preds['train_preds'] = train_preds\n",
    "X_test_preds['test_preds'] = test_preds\n",
    "\n",
    "# Scale the predictions\n",
    "X_train_preds_rescaled = pd.DataFrame(scaler.inverse_transform(X_train_preds), columns=X_train_preds.columns)\n",
    "X_test_preds_rescaled = pd.DataFrame(scaler.inverse_transform(X_test_preds), columns=X_test_preds.columns)\n",
    "\n",
    "# Change the index of the rescaled test preditions to be able to concatenate later\n",
    "startindex = X_train.shape[0]\n",
    "X_test_preds_rescaled.index = pd.RangeIndex(start=startindex, stop=startindex + len(X_test_preds_rescaled), step=1)"
   ],
   "metadata": {
    "id": "Hrqwx8FTE8ov"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_test_preds_rescaled"
   ],
   "metadata": {
    "id": "NYYsv_nbLd-M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df_test"
   ],
   "metadata": {
    "id": "t2k6Hv0yTZ31"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Add the actual values\n",
    "\n",
    "pred_rescaled_train_df = pd.concat([full_df_train['Target'], X_train_preds_rescaled], axis=1)\n",
    "pred_rescaled_train_df = pred_rescaled_train_df.drop(columns = ['Close', 'Volume'])\n",
    "pred_rescaled_test_df = pd.concat([full_df_test['Target'], X_test_preds_rescaled], axis=1)\n",
    "pred_rescaled_test_df = pred_rescaled_test_df.drop(columns = ['Close', 'Volume'])"
   ],
   "metadata": {
    "id": "KiTqY9OdPxZT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pred_rescaled_test_df"
   ],
   "metadata": {
    "id": "ynphVwiFRGJ0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# interactive plot\n",
    "\n",
    "pred_df = pd.concat([pred_rescaled_train_df, pred_rescaled_test_df], axis=0, ignore_index=True)\n",
    "pred_df.insert(0, 'Date', price_volume_target_df['Date'].values)\n",
    "interactive_plot(pred_df, 'Original vs Prediction')"
   ],
   "metadata": {
    "id": "XKavlaXVS_9o"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
